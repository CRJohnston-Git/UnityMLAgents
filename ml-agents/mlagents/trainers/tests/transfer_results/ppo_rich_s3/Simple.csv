Steps,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Policy/Entropy,Environment/Episode Length,Is Training
500,0.2046584,-0.0907142423093319,-0.0907142423093319,1.416428,35.285714285714285,1.0
1000,0.08564114,-0.2933332721392314,-0.2933332721392314,1.4264128,57.22222222222222,1.0
1500,0.1758069,0.40916674335797626,0.40916674335797626,1.4293606,39.416666666666664,1.0
2000,0.2322485,0.6952941536026842,0.6952941536026842,1.4264036,28.235294117647058,1.0
2500,0.34564757,0.895185218916999,0.895185218916999,1.4047986,17.074074074074073,1.0
3000,0.5803465,0.9966666925521124,0.9966666925521124,1.3831501,11.095238095238095,1.0
3500,0.7798772,1.0339655537029793,1.0339655537029793,1.3581558,7.568965517241379,1.0
4000,0.9116678,1.055897477345589,1.055897477345589,1.337184,5.371794871794871,1.0
4500,1.0372113,1.0693939851992058,1.0693939851992058,1.3300898,4.070707070707071,1.0
5000,1.0579429,1.076106237099234,1.076106237099234,1.3038011,3.3893805309734515,1.0
5500,1.06533,1.0826667061558477,1.0826667061558477,1.2737077,2.7111111111111112,1.0
6000,1.0711827,1.0877419710159302,1.0877419710159302,1.2343633,2.232258064516129,1.0
6500,1.0777676,1.089325187396418,1.089325187396418,1.1867678,2.067484662576687,1.0
7000,1.0854119,1.0932620623532463,1.0932620623532463,1.1245282,1.6737967914438503,1.0
7500,1.0872889,1.0961244294517918,1.0961244294517918,1.0857369,1.3827751196172249,1.0
8000,1.090429,1.0984914045909355,1.0984914045909355,1.0261327,1.1551724137931034,1.0
8500,1.0939512,1.0992562228983098,1.0992562228983098,0.9596387,1.0702479338842976,1.0
9000,1.0970676,1.0990795226276668,1.0990795226276668,0.89801854,1.0920502092050208,1.0
9500,1.0985308,1.0996748208999634,1.0996748208999634,0.8374807,1.032520325203252,1.0
10000,1.098802,1.0994650449281858,1.0994650449281858,0.78894335,1.0534979423868314,1.0
