Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,0.77991897,7.0,0.010844884,1.040000081062317,1.040000081062317,1.0
1000,0.77991897,11.4,0.026193244,0.9946835916253585,0.9946835916253585,1.0
1500,0.779919,2.664233576642336,0.02958817,0.5486861623986794,0.5486861623986794,1.0
2000,0.77991897,1.7119565217391304,0.03439621,-0.08956520194592683,-0.08956520194592683,1.0
2500,0.779919,1.5876288659793814,0.03725438,-0.05010307818343959,-0.05010307818343959,1.0
3000,0.77991897,1.6972972972972973,0.037067212,-0.11902701210331272,-0.11902701210331272,1.0
3500,0.779919,1.7173913043478262,0.03692114,-0.08951085417167,-0.08951085417167,1.0
4000,0.779919,1.7322404371584699,0.037204582,0.025081984332350434,0.025081984332350434,1.0
4500,0.77991897,1.8135593220338984,0.03726187,0.051016967175370555,0.051016967175370555,1.0
5000,0.779919,1.7472527472527473,0.037428726,-0.05423075288206666,-0.05423075288206666,1.0
5500,0.779919,1.8959537572254335,0.037188705,-0.050982641346881845,-0.050982641346881845,1.0
6000,0.779919,1.8959537572254335,0.036926724,-0.0765895781489466,-0.0765895781489466,1.0
6500,0.779919,2.0609756097560976,0.037098594,-0.020548760890960693,-0.020548760890960693,1.0
7000,0.779919,2.206451612903226,0.03624804,-0.015096752874312861,-0.015096752874312861,1.0
7500,0.77991897,2.1582278481012658,0.035783876,-0.021708840056310727,-0.021708840056310727,1.0
8000,0.779919,2.391891891891892,0.035094254,-0.09878376287383002,-0.09878376287383002,1.0
8500,0.779919,2.2115384615384617,0.03563237,0.0205769447179941,0.0205769447179941,1.0
9000,0.77991897,2.2828947368421053,0.035036482,-0.00789471519620795,-0.00789471519620795,1.0
9500,0.779919,2.4551724137931035,0.03556024,0.02875864341341216,0.02875864341341216,1.0
10000,0.779919,2.535211267605634,0.034477707,-0.103450681122256,-0.103450681122256,1.0
