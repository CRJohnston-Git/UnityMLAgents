Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,1.4189386,31.0,0.054607674,-0.38399996707836787,-0.38399996707836787,1.0
1000,1.4022008,32.875,0.1791429,-0.3979999661445618,-0.3979999661445618,1.0
1500,1.3984258,31.733333333333334,0.036541026,-0.17533329799771308,-0.17533329799771308,1.0
2000,1.4013523,34.642857142857146,0.11348884,0.37500003991382463,0.37500003991382463,1.0
2500,1.3994123,48.2,0.23252645,0.3610000550746918,0.3610000550746918,1.0
3000,1.3944241,23.666666666666668,0.057335425,0.4784210912491146,0.4784210912491146,1.0
3500,1.3864775,24.954545454545453,0.13867432,0.4890476546826817,0.4890476546826817,1.0
4000,1.3735267,19.291666666666668,0.28278518,0.920000026623408,0.920000026623408,1.0
4500,1.3471564,11.692307692307692,0.65102947,0.9320513126559746,0.9320513126559746,1.0
5000,1.3261051,10.904761904761905,0.7523511,0.9459524119184131,0.9459524119184131,1.0
5500,1.3032593,7.807017543859649,0.83607864,1.0319298578981768,1.0319298578981768,1.0
6000,1.2789329,6.7384615384615385,0.9512903,1.0432308096152085,1.0432308096152085,1.0
6500,1.2387447,5.626666666666667,1.0306185,1.0385333772748708,1.0385333772748708,1.0
7000,1.1981913,4.329787234042553,1.0340439,1.0667021781840222,1.0667021781840222,1.0
7500,1.1823674,4.1875,1.0493842,1.067916713654995,1.067916713654995,1.0
8000,1.1717753,3.5045045045045047,1.0593039,1.0749549983857989,1.0749549983857989,1.0
8500,1.145088,2.8384615384615386,1.065126,1.0815385029866145,1.0815385029866145,1.0
9000,1.0935551,2.5034965034965033,1.0750359,1.0851049323182005,1.0851049323182005,1.0
9500,1.0672665,2.289473684210526,1.0799996,1.086973720475247,1.086973720475247,1.0
10000,1.0315814,1.9820359281437125,1.0821214,1.0902395533944318,1.0902395533944318,1.0
