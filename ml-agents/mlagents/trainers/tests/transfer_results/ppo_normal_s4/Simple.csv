Steps,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Policy/Entropy,Environment/Episode Length,Is Training
500,0.45050907,-0.3916666346291701,-0.3916666346291701,1.4189383,42.416666666666664,1.0
1000,-5.5588207e-05,0.056000061146914956,0.056000061146914956,1.418989,47.1,1.0
1500,0.14946598,0.44684214193962124,0.44684214193962124,1.4066797,25.473684210526315,1.0
2000,0.2616328,0.35900005474686625,0.35900005474686625,1.3826516,53.1,1.0
2500,0.34226987,0.7260869903408963,0.7260869903408963,1.3611218,19.391304347826086,1.0
3000,0.47563735,0.9143333531916141,0.9143333531916141,1.3340548,15.333333333333334,1.0
3500,0.73112303,1.0244231075048447,1.0244231075048447,1.3088727,8.576923076923077,1.0
4000,0.8563113,1.0412500379607081,1.0412500379607081,1.2883761,6.859375,1.0
4500,0.98677695,1.053866708278656,1.053866708278656,1.2832565,5.613333333333333,1.0
5000,1.0389698,1.0765517610928108,1.0765517610928108,1.2509315,3.3017241379310347,1.0
5500,1.0647529,1.085986430953149,1.085986430953149,1.2313579,2.401360544217687,1.0
6000,1.0799944,1.087597437493213,1.087597437493213,1.208137,2.24025974025974,1.0
6500,1.0834103,1.09041423416702,1.09041423416702,1.1795932,1.9585798816568047,1.0
7000,1.0898198,1.093064546585083,1.093064546585083,1.1346892,1.6989247311827957,1.0
7500,1.0886377,1.092178802250484,1.092178802250484,1.1161077,1.7988826815642458,1.0
8000,1.0891898,1.0946464935938518,1.0946464935938518,1.0806593,1.5151515151515151,1.0
8500,1.0908219,1.0955882633433622,1.0955882633433622,1.038606,1.4509803921568627,1.0
9000,1.0928746,1.096255951583103,1.096255951583103,0.99718565,1.3649289099526067,1.0
9500,1.0952178,1.0973303431299477,1.0973303431299477,0.9419983,1.2669683257918551,1.0
10000,1.0966871,1.0980616996992,1.0980616996992,0.90307087,1.198237885462555,1.0
