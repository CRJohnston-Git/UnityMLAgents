Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,1.4189383,47.666666666666664,-0.056646775,-0.5999999559587903,-0.5999999559587903,1.0
1000,1.4297603,33.3125,-0.08239883,-0.40249996399506927,-0.40249996399506927,1.0
1500,1.4407852,50.9,-0.08760901,-0.539999950884117,-0.539999950884117,1.0
2000,1.4525805,32.375,-0.09330809,0.2506250493461266,0.2506250493461266,1.0
2500,1.4519507,26.11764705882353,0.01821129,0.25117650978705464,0.25117650978705464,1.0
3000,1.4432425,19.48,0.086323336,0.7340000396966935,0.7340000396966935,1.0
3500,1.4351099,16.862068965517242,0.24466644,0.8279310708929752,0.8279310708929752,1.0
4000,1.4250828,11.702702702702704,0.36455515,0.8681081392475076,0.8681081392475076,1.0
4500,1.3902757,6.492537313432836,0.58702046,1.0438806379019325,1.0438806379019325,1.0
5000,1.3748772,5.291139240506329,0.77541316,1.0565823195855828,1.0565823195855828,1.0
5500,1.3449776,4.13265306122449,0.92098695,1.0574490230492488,1.0574490230492488,1.0
6000,1.3121973,3.5272727272727273,1.0306343,1.0746364084157076,1.0746364084157076,1.0
6500,1.2859037,3.299145299145299,1.0586494,1.0772650017697587,1.0772650017697587,1.0
7000,1.2230195,2.9523809523809526,1.0700891,1.0803175019839453,1.0803175019839453,1.0
7500,1.1742543,2.4178082191780823,1.0734833,1.08582195517135,1.08582195517135,1.0
8000,1.12955,2.0303030303030303,1.0766981,1.0895757913589477,1.0895757913589477,1.0
8500,1.0903392,1.7472527472527473,1.0831246,1.0925824484982334,1.0925824484982334,1.0
9000,1.055769,1.446078431372549,1.0879617,1.0955392437822677,1.0955392437822677,1.0
9500,1.0099914,1.2727272727272727,1.0923996,1.0972272992134093,1.0972272992134093,1.0
10000,0.9655406,1.1645021645021645,1.094048,1.098355003765651,1.098355003765651,1.0
