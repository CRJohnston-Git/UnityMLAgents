Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,1.4189384,28.642857142857142,-0.132539,-0.12785712469901359,-0.12785712469901359,1.0
1000,1.4063991,40.666666666666664,-0.2972711,0.24357146929417337,0.24357146929417337,1.0
1500,1.4094983,33.285714285714285,-0.11602719,0.19571432311620032,0.19571432311620032,1.0
2000,1.4269212,22.333333333333332,-0.03105951,0.7319047788069362,0.7319047788069362,1.0
2500,1.4306228,12.432432432432432,0.27560836,0.7983784053373981,0.7983784053373981,1.0
3000,1.4138105,10.272727272727273,0.39153564,0.9818182109262455,0.9818182109262455,1.0
3500,1.4062147,7.754385964912281,0.66669095,1.013157929898354,1.013157929898354,1.0
4000,1.4104147,6.920634920634921,0.8078241,1.0400000394336761,1.0400000394336761,1.0
4500,1.4003717,5.048192771084337,1.0017221,1.0601205222577934,1.0601205222577934,1.0
5000,1.3827659,5.291139240506329,1.0498197,1.0574683931809437,1.0574683931809437,1.0
5500,1.3471165,3.9313725490196076,1.0646499,1.070196119593639,1.070196119593639,1.0
6000,1.3021044,3.247863247863248,1.0687311,1.0773504707548354,1.0773504707548354,1.0
6500,1.2581674,2.5492957746478875,1.0699016,1.084577502499164,1.084577502499164,1.0
7000,1.2067466,2.241830065359477,1.0921195,1.0873856567869,1.0873856567869,1.0
7500,1.1798576,2.0059880239520957,1.0932637,1.0900599135610158,1.0900599135610158,1.0
8000,1.159288,1.782122905027933,1.0872855,1.092122936381974,1.092122936381974,1.0
8500,1.1431692,1.7472527472527473,1.0832174,1.0925824484982334,1.0925824484982334,1.0
9000,1.0988758,1.4509803921568627,1.0702798,1.095441204660079,1.095441204660079,1.0
9500,1.0558571,1.352112676056338,1.0820524,1.0964319521272685,1.0964319521272685,1.0
10000,1.0122726,1.2935779816513762,1.0885781,1.097064246825122,1.097064246825122,1.0
