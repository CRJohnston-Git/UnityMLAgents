Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,1.4189384,28.642857142857142,-0.43766326,-0.12785712469901359,-0.12785712469901359,1.0
1000,1.4304953,64.22222222222223,-0.42201748,0.03375007398426533,0.03375007398426533,1.0
1500,1.4307939,36.0,-0.38405997,-0.3021428217845304,-0.3021428217845304,1.0
2000,1.4221725,40.5,-0.33886567,0.2666667054096858,0.2666667054096858,1.0
2500,1.4012045,25.842105263157894,-0.18812817,0.38789475395491246,0.38789475395491246,1.0
3000,1.3781503,15.379310344827585,0.020163111,0.7886207160250894,0.7886207160250894,1.0
3500,1.3589201,17.555555555555557,0.14267263,0.7688889155785242,0.7688889155785242,1.0
4000,1.3407634,11.425,0.33573276,0.9665000300854445,0.9665000300854445,1.0
4500,1.3298187,7.5423728813559325,0.6817156,1.0345763079190657,1.0345763079190657,1.0
5000,1.3236454,7.5344827586206895,0.800179,1.0358621097844223,1.0358621097844223,1.0
5500,1.3021436,7.35,0.8830002,1.0181667052209378,1.0181667052209378,1.0
6000,1.2764632,5.756756756756757,0.96151567,1.0509459859616048,1.0509459859616048,1.0
6500,1.2613353,4.651685393258427,0.9977106,1.0640449925754847,1.0640449925754847,1.0
7000,1.2269579,4.376344086021505,1.0375782,1.0659140233070619,1.0659140233070619,1.0
7500,1.1901405,3.7523809523809524,1.050694,1.072476237160819,1.072476237160819,1.0
8000,1.1560534,3.310344827586207,1.0593795,1.07681038872949,1.07681038872949,1.0
8500,1.126217,2.9682539682539684,1.0655472,1.0803175019839453,1.0803175019839453,1.0
9000,1.0649645,2.58273381294964,1.0721475,1.0842446431839208,1.0842446431839208,1.0
9500,1.0344383,2.1055900621118013,1.0777699,1.0888820220224606,1.0888820220224606,1.0
10000,1.0140263,1.9181286549707601,1.0829353,1.0907017870953208,1.0907017870953208,1.0
