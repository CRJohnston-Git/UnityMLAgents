Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,1.4189384,-0.29621762,49.8,-0.6499999546342425,-0.6499999546342425,1.0
1000,1.4113789,-0.31202954,34.23076923076923,-0.017857107599931105,-0.017857107599931105,1.0
1500,1.4020493,-0.24216123,29.294117647058822,0.2294118023094009,0.2294118023094009,1.0
2000,1.3925049,-0.12500052,28.555555555555557,0.4276471015285043,0.4276471015285043,1.0
2500,1.3772353,0.054095764,15.366666666666667,0.7686666905879974,0.7686666905879974,1.0
3000,1.3588246,0.1888788,14.59375,0.9278125313576311,0.9278125313576311,1.0
3500,1.3397152,0.3559211,12.078947368421053,0.9902631797288594,0.9902631797288594,1.0
4000,1.3188759,0.49442014,8.181818181818182,1.0070909366688945,1.0070909366688945,1.0
4500,1.2826816,0.7257226,6.185714285714286,1.0490000409739357,1.0490000409739357,1.0
5000,1.2677653,0.88025546,5.441558441558442,1.0546753700677451,1.0546753700677451,1.0
5500,1.2531288,0.96128184,4.584269662921348,1.0640449898966242,1.0640449898966242,1.0
6000,1.2316496,1.0148216,3.99,1.0699000471830369,1.0699000471830369,1.0
6500,1.1945636,1.0467741,3.2457627118644066,1.0777119074837636,1.0777119074837636,1.0
7000,1.1417608,1.0617256,2.6911764705882355,1.0830147459226496,1.0830147459226496,1.0
7500,1.11352,1.0711502,2.3945578231292517,1.0859864317640966,1.0859864317640966,1.0
8000,1.0905806,1.0766755,2.1847133757961785,1.0882165955889755,1.0882165955889755,1.0
8500,1.0680295,1.0816191,2.099378881987578,1.0890062455064762,1.0890062455064762,1.0
9000,1.0097134,1.0853155,1.7173913043478262,1.0927174220914426,1.0927174220914426,1.0
9500,0.9727085,1.0885838,1.726775956284153,1.0927869159667218,1.0927869159667218,1.0
10000,0.9496406,1.090134,1.631578947368421,1.093631608862626,1.093631608862626,1.0
