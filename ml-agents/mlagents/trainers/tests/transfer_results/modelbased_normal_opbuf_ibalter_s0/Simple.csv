Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,1.4189384,36.25,-0.0027558792,-0.4549999665468931,-0.4549999665468931,1.0
1000,1.40143,36.6,-0.050624397,0.3364286300327097,0.3364286300327097,1.0
1500,1.3881391,34.07142857142857,-0.019971816,0.44142860706363407,0.44142860706363407,1.0
2000,1.3747299,27.055555555555557,0.028244533,0.41611115261912346,0.41611115261912346,1.0
2500,1.3462697,14.030303030303031,0.17152269,0.9003030556169423,0.9003030556169423,1.0
3000,1.3336747,12.31578947368421,0.39640433,0.9273684538508716,0.9273684538508716,1.0
3500,1.3203485,9.10204081632653,0.61531305,1.0179592212852167,1.0179592212852167,1.0
4000,1.306676,6.294117647058823,0.8029135,1.0142647456651663,1.0142647456651663,1.0
4500,1.2839947,6.552238805970149,0.91885394,1.0447761576567123,1.0447761576567123,1.0
5000,1.273725,5.1875,0.9399028,1.0578750476241112,1.0578750476241112,1.0
5500,1.2618711,4.329787234042553,1.0212258,1.0665957915022017,1.0665957915022017,1.0
6000,1.240845,3.7714285714285714,1.0559676,1.0722857577460152,1.0722857577460152,1.0
6500,1.2025492,3.3947368421052633,1.0465837,1.0761403964276899,1.0761403964276899,1.0
7000,1.1982858,2.557142857142857,1.0702845,1.084285753113883,1.084285753113883,1.0
7500,1.16528,2.2828947368421053,1.0755836,1.087105299297132,1.087105299297132,1.0
8000,1.1418766,2.1582278481012658,1.0797303,1.088481047485448,1.088481047485448,1.0
8500,1.1254944,1.8735632183908046,1.081765,1.091206928779339,1.091206928779339,1.0
9000,1.0868304,1.6595744680851063,1.0580043,1.0934574768898335,1.0934574768898335,1.0
9500,1.0779132,1.4729064039408868,1.1305122,1.0952709643124359,1.0952709643124359,1.0
10000,1.0650005,1.4702970297029703,1.1205382,1.0952970580299302,1.0952970580299302,1.0
