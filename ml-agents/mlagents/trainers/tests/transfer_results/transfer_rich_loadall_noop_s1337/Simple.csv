Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,0.779919,24.0,0.72882426,0.8700000047683716,0.8700000047683716,1.0
1000,0.779919,70.0,0.70938665,-1.3246153042866633,-1.3246153042866633,1.0
1500,0.7799191,17.333333333333332,0.543621,-0.010370341715989289,-0.010370341715989289,1.0
2000,0.779919,10.69047619047619,0.6379992,-0.11071425534430004,-0.11071425534430004,1.0
2500,0.779919,9.326530612244898,0.7577243,0.428367373894672,0.428367373894672,1.0
3000,0.77991897,9.955555555555556,0.5662075,-0.2753333197699653,-0.2753333197699653,1.0
3500,0.779919,10.904761904761905,0.5359071,-0.15999998365129744,-0.15999998365129744,1.0
4000,0.779919,10.133333333333333,0.5057968,-0.07688887384202746,-0.07688887384202746,1.0
4500,0.77991897,8.596153846153847,0.54825026,0.08365386036726144,0.08365386036726144,1.0
5000,0.779919,8.277777777777779,0.3555654,-0.039999977306083394,-0.039999977306083394,1.0
5500,0.779919,7.568965517241379,0.24787979,-0.07706894545719542,-0.07706894545719542,1.0
6000,0.779919,6.968253968253968,0.20193367,0.018730183442433674,0.018730183442433674,1.0
6500,0.779919,5.4935064935064934,0.0163807,-0.06948048882670217,-0.06948048882670217,1.0
7000,0.779919,5.693333333333333,0.12585363,0.07626670201619466,0.07626670201619466,1.0
7500,0.779919,5.5394736842105265,0.06913075,0.003157923096104672,0.003157923096104672,1.0
8000,0.77991897,5.397435897435898,0.14491437,0.11666669906714024,0.11666669906714024,1.0
8500,0.77991897,4.595505617977528,-0.06664321,-0.0838201983591144,-0.0838201983591144,1.0
9000,0.779919,4.883720930232558,0.018258411,0.05476747349251148,0.05476747349251148,1.0
9500,0.7799191,3.3805309734513274,-0.20429213,-0.1225663423538208,-0.1225663423538208,1.0
10000,0.779919,3.356521739130435,-0.16617383,-0.13947823358618694,-0.13947823358618694,1.0
