Steps,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Policy/Entropy,Environment/Episode Length,Is Training
500,0.183802,-0.04444438136286206,-0.04444438136286206,1.414326,60.25,1.0
1000,0.04053989,-0.19214282504149846,-0.19214282504149846,1.4191244,35.53333333333333,1.0
1500,0.0825794,0.1641666969905297,0.1641666969905297,1.4286938,28.727272727272727,1.0
2000,0.04157916,0.3754545964977958,0.3754545964977958,1.4398553,52.833333333333336,1.0
2500,0.17656313,0.7846154226706579,0.7846154226706579,1.4560745,18.576923076923077,1.0
3000,0.45014364,0.9510345109577837,0.9510345109577837,1.4312209,16.689655172413794,1.0
3500,0.5221687,0.9606522007480912,0.9606522007480912,1.417977,9.391304347826088,1.0
4000,0.7150543,1.0096364026719873,1.0096364026719873,1.4046891,8.036363636363637,1.0
4500,0.7965957,1.0455882680766724,1.0455882680766724,1.38225,6.382352941176471,1.0
5000,0.9267594,1.0612941580660202,1.0612941580660202,1.3530825,4.905882352941177,1.0
5500,1.018622,1.0604819720049938,1.0604819720049938,1.3236883,5.036144578313253,1.0
6000,1.0518546,1.0651087398114412,1.0651087398114412,1.2912983,4.3478260869565215,1.0
6500,1.0526184,1.0747748205253669,1.0747748205253669,1.2554266,3.5495495495495497,1.0
7000,1.0650564,1.079180371565897,1.079180371565897,1.2110672,3.057377049180328,1.0
7500,1.0699507,1.0842446431839208,1.0842446431839208,1.1644014,2.597122302158273,1.0
8000,1.0878711,1.0854109966591612,1.0854109966591612,1.1417867,2.4383561643835616,1.0
8500,1.0791808,1.088280289795748,1.088280289795748,1.1194208,2.171974522292994,1.0
9000,1.0305645,1.0895757913589477,1.0895757913589477,1.0736086,2.0424242424242425,1.0
9500,1.0950004,1.0913793424080158,1.0913793424080158,1.0578723,1.8620689655172413,1.0
10000,1.0913229,1.0926776264534621,1.0926776264534621,1.0299456,1.7322404371584699,1.0
