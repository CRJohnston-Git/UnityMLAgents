Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,1.4189383,35.57142857142857,0.31689397,-0.18846148481735817,-0.18846148481735817,1.0
1000,1.4033861,36.53846153846154,0.07742216,-0.027692265808582306,-0.027692265808582306,1.0
1500,1.3946286,34.23076923076923,0.27339023,0.45642861457807676,0.45642861457807676,1.0
2000,1.3919603,33.5625,0.2692105,0.6440000356485446,0.6440000356485446,1.0
2500,1.3655249,14.151515151515152,0.3071981,0.8200000348416242,0.8200000348416242,1.0
3000,1.3418032,11.3,0.47071734,0.9960000365972519,0.9960000365972519,1.0
3500,1.314781,7.655172413793103,0.68594205,1.0339655516476467,1.0339655516476467,1.0
4000,1.2825673,6.397058823529412,0.8432144,1.0457353293895721,1.0457353293895721,1.0
4500,1.2346874,4.417582417582418,1.0059158,1.0651648856781342,1.0651648856781342,1.0
5000,1.2174089,3.8076923076923075,1.0465561,1.0717308154472938,1.0717308154472938,1.0
5500,1.1929674,3.1487603305785123,1.0617487,1.0785950836071299,1.0785950836071299,1.0
6000,1.1601065,2.58273381294964,1.0692488,1.083956873674187,1.083956873674187,1.0
6500,1.1116868,2.3178807947019866,1.0803926,1.0869536786679401,1.0869536786679401,1.0
7000,1.0444043,1.9642857142857142,1.0848447,1.0902976521423884,1.0902976521423884,1.0
7500,1.0008249,1.7988826815642458,1.0857288,1.0920112046449544,1.0920112046449544,1.0
8000,0.955066,1.7417582417582418,1.0877,1.0925824484982334,1.0925824484982334,1.0
8500,0.90634423,1.6455026455026456,1.0903695,1.0934920935403734,1.0934920935403734,1.0
9000,0.8492546,1.5226130653266332,1.0901868,1.0948241493809763,1.0948241493809763,1.0
9500,0.8056545,1.278538812785388,1.0921546,1.0971689763134473,1.0971689763134473,1.0
10000,0.7602477,1.1645021645021645,1.0941327,1.098355003765651,1.098355003765651,1.0
