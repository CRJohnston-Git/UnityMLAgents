Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,1.4189386,44.333333333333336,-0.055464976,-0.42363631318915973,-0.42363631318915973,1.0
1000,1.4001544,32.357142857142854,0.16476792,-0.03642852604389191,-0.03642852604389191,1.0
1500,1.4095477,30.625,0.25286216,0.7312500467523932,0.7312500467523932,1.0
2000,1.4276391,15.4,0.2890753,0.6203333613773186,0.6203333613773186,1.0
2500,1.4072034,13.628571428571428,0.4181833,0.8511428873453821,0.8511428873453821,1.0
3000,1.3664961,8.64,0.70760375,0.9984000340104103,0.9984000340104103,1.0
3500,1.3492923,5.72972972972973,0.844574,1.0517567935827616,1.0517567935827616,1.0
4000,1.3384088,5.023809523809524,0.9847146,1.060119092464447,1.060119092464447,1.0
4500,1.3323182,4.5,1.0329238,1.0644444896115197,1.0644444896115197,1.0
5000,1.2939434,3.024193548387097,1.0525593,1.0799193978309631,1.0799193978309631,1.0
5500,1.2777714,2.5899280575539567,1.0641272,1.0840288160516203,1.0840288160516203,1.0
6000,1.2487831,2.5211267605633805,1.0722656,1.0847183482747682,1.0847183482747682,1.0
6500,1.2050028,2.34,1.0765142,1.0866000366210937,1.0866000366210937,1.0
7000,1.1549641,1.7833333333333334,1.0783265,1.0921666979789735,1.0921666979789735,1.0
7500,1.109201,1.5510204081632653,1.0847218,1.0944898250151653,1.0944898250151653,1.0
8000,1.0633873,1.52020202020202,1.0877984,1.094747503598531,1.094747503598531,1.0
8500,1.0129825,1.2889908256880733,1.0903869,1.0971101183410084,1.0971101183410084,1.0
9000,0.95023376,1.2522522522522523,1.0943755,1.0974775037250004,1.0974775037250004,1.0
9500,0.90708816,1.2070484581497798,1.095987,1.0979295412349281,1.0979295412349281,1.0
10000,0.86569697,1.0791666666666666,1.0973964,1.0992083579301835,1.0992083579301835,1.0
