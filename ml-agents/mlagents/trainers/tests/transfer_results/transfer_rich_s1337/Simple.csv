Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,0.779919,24.0,-0.041320935,0.8700000047683716,0.8700000047683716,1.0
1000,0.7982444,13.405797101449275,0.021330258,0.9788235706441543,0.9788235706441543,1.0
1500,0.7940397,3.256637168141593,0.49465078,0.3084070999010474,0.3084070999010474,1.0
2000,0.7781704,1.564102564102564,0.6558233,-0.0668204998358702,-0.0668204998358702,1.0
2500,0.78080714,1.8901734104046244,0.5397697,-0.025260097718652272,-0.025260097718652272,1.0
3000,0.791759,1.788888888888889,0.480351,-0.11655553976694742,-0.11655553976694742,1.0
3500,0.7936098,1.9470588235294117,0.42608535,-0.05847057104110718,-0.05847057104110718,1.0
4000,0.7949605,2.171974522292994,0.32811213,-0.014968134035730059,-0.014968134035730059,1.0
4500,0.8010196,2.425675675675676,0.20368168,0.021216236256264353,0.021216236256264353,1.0
5000,0.7918733,2.613138686131387,0.014620112,-0.050729908212258,-0.050729908212258,1.0
5500,0.7736358,2.7669172932330826,0.02043997,-0.0025563697169597886,-0.0025563697169597886,1.0
6000,0.76135683,2.5942028985507246,0.013675219,-0.01014490576757901,-0.01014490576757901,1.0
6500,0.7567113,3.1487603305785123,-0.04550316,-0.11363634196194736,-0.11363634196194736,1.0
7000,0.76707715,2.4895104895104896,-0.04957128,-0.15720277566176194,-0.15720277566176194,1.0
7500,0.7842571,2.178343949044586,0.03699396,-0.014522273829028865,-0.014522273829028865,1.0
8000,0.78056604,2.4246575342465753,0.04320102,0.021164405835817936,0.021164405835817936,1.0
8500,0.78015476,2.462068965517241,-0.005532019,-0.01682756604819462,-0.01682756604819462,1.0
9000,0.80084985,2.3783783783783785,-0.06948464,-0.0987837636792982,-0.0987837636792982,1.0
9500,0.79060847,2.2745098039215685,0.05410402,0.02816995608261208,0.02816995608261208,1.0
10000,0.78891873,2.1656050955414012,0.0012564264,-0.043120999245127294,-0.043120999245127294,1.0
