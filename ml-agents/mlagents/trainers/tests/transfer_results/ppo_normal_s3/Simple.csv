Steps,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Policy/Entropy,Environment/Episode Length,Is Training
500,0.18788125,-0.2676922592979211,-0.2676922592979211,1.4189383,37.92307692307692,1.0
1000,0.054781727,0.16545458561317486,0.16545458561317486,1.4104409,33.8,1.0
1500,0.11332412,0.04727280410853299,0.04727280410853299,1.4019066,56.0,1.0
2000,0.1306322,0.7155555962688394,0.7155555962688394,1.3941978,24.72222222222222,1.0
2500,0.23349014,0.9200000381469726,0.9200000381469726,1.3873938,19.166666666666668,1.0
3000,0.4153727,0.9705882703556734,0.9705882703556734,1.3907564,14.028571428571428,1.0
3500,0.65899956,1.010000035814617,1.010000035814617,1.3664708,9.717391304347826,1.0
4000,0.7539586,1.0432308022792522,1.0432308022792522,1.3348167,6.6923076923076925,1.0
4500,0.949506,1.0533784217125661,1.0533784217125661,1.3101846,5.756756756756757,1.0
5000,1.0071468,1.0637778202692667,1.0637778202692667,1.288276,4.566666666666666,1.0
5500,1.0524871,1.0693939827909373,1.0693939827909373,1.2657138,4.01010101010101,1.0
6000,1.0627782,1.0730189141237512,1.0730189141237512,1.2410226,3.7169811320754715,1.0
6500,1.0654343,1.0780833770831426,1.0780833770831426,1.2124375,3.1666666666666665,1.0
7000,1.0721259,1.0858904482567147,1.0858904482567147,1.1581945,2.4178082191780823,1.0
7500,1.0787783,1.0883544653276853,1.0883544653276853,1.1129012,2.1645569620253164,1.0
8000,1.0824796,1.0906433076189275,1.0906433076189275,1.0740321,1.9298245614035088,1.0
8500,1.0864006,1.0936508235477267,1.0936508235477267,1.0420654,1.6402116402116402,1.0
9000,1.0882088,1.0956310959695612,1.0956310959695612,1.0200481,1.4320388349514563,1.0
9500,1.0891808,1.097260300427267,1.097260300427267,0.96725786,1.278538812785388,1.0
10000,1.0919034,1.098547033774547,1.098547033774547,0.90387,1.141025641025641,1.0
