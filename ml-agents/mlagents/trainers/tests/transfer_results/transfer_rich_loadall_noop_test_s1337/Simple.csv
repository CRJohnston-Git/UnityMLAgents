Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,0.779919,24.0,0.72882426,0.8700000047683716,0.8700000047683716,1.0
1000,0.7884923,None,0.7026417,None,None,1.0
1500,0.77895665,654.5,0.594681,-5.989999271929264,-5.989999271929264,1.0
2000,0.76049995,None,0.49216735,None,None,1.0
2500,0.74925315,None,0.33024108,None,None,1.0
3000,0.7454424,None,0.23883946,None,None,1.0
3500,0.7469143,None,0.15123767,None,None,1.0
4000,0.75590295,None,0.025847662,None,None,1.0
4500,0.714388,None,-0.060126737,None,None,1.0
5000,0.6990057,None,-0.1246142,None,None,1.0
5500,0.68772644,None,-0.18666118,None,None,1.0
6000,0.6749326,None,-0.26957515,None,None,1.0
6500,0.68527853,None,-0.32964855,None,None,1.0
7000,0.69639003,5231.0,-0.38090545,-52.30999398231506,-52.30999398231506,1.0
7500,0.7104888,545.0,-0.43677294,-5.449999392032623,-5.449999392032623,1.0
8000,0.73800695,126.5,-0.50248903,-1.2649998605872195,-1.2649998605872195,1.0
8500,0.74836975,38.25,-0.25460422,0.2980000431338946,0.2980000431338946,1.0
9000,0.7517259,20.833333333333332,-0.18498598,0.28916668767730397,0.28916668767730397,1.0
