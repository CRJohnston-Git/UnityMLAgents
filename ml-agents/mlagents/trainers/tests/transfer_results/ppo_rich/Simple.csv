Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,1.4189384,-0.07036922,41.333333333333336,-0.20909086005254227,-0.20909086005254227,1.0
1000,1.433734,-0.07402871,22.434782608695652,0.3078261119030092,0.3078261119030092,1.0
1500,1.435478,0.04086134,29.666666666666668,0.45000003774960834,0.45000003774960834,1.0
2000,1.4252425,0.12336006,17.448275862068964,0.815517261110503,0.815517261110503,1.0
2500,1.4231224,0.36351836,12.969696969696969,0.8684848681318037,0.8684848681318037,1.0
3000,1.4043651,0.5265908,9.595744680851064,1.014255334722235,1.014255334722235,1.0
3500,1.3891138,0.7155167,7.225806451612903,1.0390322958269427,1.0390322958269427,1.0
4000,1.3774318,0.8672002,5.662162162162162,1.0520270668171547,1.0520270668171547,1.0
4500,1.3685534,0.9530288,4.904761904761905,1.0610714696702503,1.0610714696702503,1.0
5000,1.3322457,1.027474,4.21875,1.0676042139530182,1.0676042139530182,1.0
5500,1.2994994,1.0520626,3.23728813559322,1.077457672458584,1.077457672458584,1.0
6000,1.2616261,1.0660787,2.8091603053435112,1.0819084371319254,1.0819084371319254,1.0
6500,1.2156883,1.072196,2.3466666666666667,1.0865333700180053,1.0865333700180053,1.0
7000,1.1592442,1.0820519,2.151898734177215,1.088481047485448,1.088481047485448,1.0
7500,1.116626,1.0826049,1.8901734104046244,1.0910404948140844,1.0910404948140844,1.0
8000,1.0648979,1.0846608,1.5958549222797926,1.0940414803015754,1.0940414803015754,1.0
8500,1.011379,1.0892507,1.5175879396984924,1.0948744005893343,1.0948744005893343,1.0
9000,0.9667084,1.0925853,1.3317757009345794,1.0966355410691733,1.0966355410691733,1.0
9500,0.91629153,1.0934478,1.2669683257918551,1.0973755919555732,1.0973755919555732,1.0
10000,0.86952144,1.0944226,1.1373390557939915,1.0985837161796799,1.0985837161796799,1.0
