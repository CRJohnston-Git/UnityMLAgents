Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,1.4189384,28.642857142857142,-0.43766326,-0.12785712469901359,-0.12785712469901359,1.0
1000,1.4301617,64.22222222222223,-0.42681703,0.03375007398426533,0.03375007398426533,1.0
1500,1.4310416,31.416666666666668,-0.39313355,-0.2430768947188671,-0.2430768947188671,1.0
2000,1.4237176,43.785714285714285,-0.3679527,0.24923082154530746,0.24923082154530746,1.0
2500,1.4146978,25.842105263157894,-0.26312917,0.21263160909477033,0.21263160909477033,1.0
3000,1.4095443,25.444444444444443,-0.04600092,0.530000030166573,0.530000030166573,1.0
3500,1.3992968,18.92,-0.03210292,0.7420000213384629,0.7420000213384629,1.0
4000,1.3829602,15.8,0.07506181,0.7630000169078509,0.7630000169078509,1.0
4500,1.3789508,11.365853658536585,0.51765805,0.970243922275741,0.970243922275741,1.0
5000,1.3699678,11.0,0.6509672,0.9995122203012792,0.9995122203012792,1.0
5500,1.3575017,8.634615384615385,0.73874635,0.9803846495655867,0.9803846495655867,1.0
6000,1.3423617,7.508474576271187,0.8560103,1.0159322452747215,1.0159322452747215,1.0
6500,1.3342063,5.875,0.92204124,1.0511111459798284,1.0511111459798284,1.0
7000,1.3261026,5.930555555555555,0.9787566,1.0351389289523165,1.0351389289523165,1.0
7500,1.3197871,5.25,1.0103531,1.0578750409185886,1.0578750409185886,1.0
8000,1.3126576,4.308510638297872,1.0318139,1.066170257456759,1.066170257456759,1.0
8500,1.3013153,3.9405940594059405,1.0376474,1.0708911359900295,1.0708911359900295,1.0
9000,1.2975057,3.9705882352941178,1.060301,1.0706863216325349,1.0706863216325349,1.0
9500,1.2921487,3.8155339805825244,1.0544285,1.0712621790691488,1.0712621790691488,1.0
10000,1.2888044,3.9405940594059405,1.0565617,1.070495092042602,1.070495092042602,1.0
