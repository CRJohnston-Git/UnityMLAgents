Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
500,1.4189384,31.142857142857142,-0.57439536,0.3228571665074144,0.3228571665074144,1.0
1000,1.4145045,29.58823529411765,-0.4597559,0.03058826265966191,0.03058826265966191,1.0
1500,1.4200764,24.38095238095238,-0.32021514,0.3585000354796648,0.3585000354796648,1.0
2000,1.4360713,20.833333333333332,-0.2746155,0.6450000243882338,0.6450000243882338,1.0
2500,1.422917,22.045454545454547,-0.09030145,0.7395454970273104,0.7395454970273104,1.0
3000,1.416067,11.702702702702704,0.0985653,0.8883784131423847,0.8883784131423847,1.0
3500,1.396016,11.45,0.27534944,0.9967500329017639,0.9967500329017639,1.0
4000,1.3618401,7.754385964912281,0.3961901,0.9928070450561088,0.9928070450561088,1.0
4500,1.3135763,6.676923076923077,0.84362024,1.0256923447434718,1.0256923447434718,1.0
5000,1.2952778,5.666666666666667,0.94018126,1.0536000410715738,1.0536000410715738,1.0
5500,1.2833147,5.036144578313253,0.9985838,1.0596385993153217,1.0596385993153217,1.0
6000,1.2688586,4.308510638297872,1.0263048,1.0663830194067447,1.0663830194067447,1.0
6500,1.2288373,3.5267857142857144,1.0423436,1.0751786114914077,1.0751786114914077,1.0
7000,1.1796116,2.9285714285714284,1.0577484,1.080555594156659,1.080555594156659,1.0
7500,1.1339939,2.5714285714285716,1.0680568,1.084142896107265,1.084142896107265,1.0
8000,1.095669,2.507042253521127,1.0744143,1.0848591932108704,1.0848591932108704,1.0
8500,1.0706488,2.1772151898734178,1.0787178,1.0882278824154334,1.0882278824154334,1.0
9000,1.0269624,1.8135593220338984,1.0828592,1.0918644383802252,1.0918644383802252,1.0
9500,0.9832885,1.7988826815642458,1.0845519,1.0920670705134643,1.0920670705134643,1.0
10000,0.9547503,1.6263157894736842,1.0882621,1.09368424039138,1.09368424039138,1.0
