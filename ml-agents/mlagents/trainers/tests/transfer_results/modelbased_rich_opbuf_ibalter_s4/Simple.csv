Steps,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Policy/Entropy,Environment/Episode Length,Is Training
500,0.17800774,-0.1799999177455902,-0.1799999177455902,1.4177536,61.5,1.0
1000,-0.07406408,-0.40999993764691883,-0.40999993764691883,1.3898563,50.2,1.0
1500,0.07094943,0.0521428899041244,0.0521428899041244,1.3890864,35.07142857142857,1.0
2000,0.024749594,-0.036428525511707575,-0.036428525511707575,1.3971605,35.285714285714285,1.0
2500,0.040108733,0.5717647483243662,0.5717647483243662,1.3831022,27.529411764705884,1.0
3000,0.25417984,0.8902702994040541,0.8902702994040541,1.371392,12.81081081081081,1.0
3500,0.4401077,0.9488571852445602,0.9488571852445602,1.353301,12.8,1.0
4000,0.5177532,1.0145833653708298,1.0145833653708298,1.3345407,9.5,1.0
4500,0.7305308,1.0265151879778414,1.0265151879778414,1.3202773,6.53030303030303,1.0
5000,0.90355587,1.037297340411995,1.037297340411995,1.3017597,5.72972972972973,1.0
5500,0.98100656,1.0507954999338835,1.0507954999338835,1.2731574,4.715909090909091,1.0
6000,1.0156021,1.0575510647375972,1.0575510647375972,1.2473227,4.061224489795919,1.0
6500,1.0362009,1.0755752673191308,1.0755752673191308,1.2290939,3.4513274336283186,1.0
7000,1.0611786,1.0810156660154462,1.0810156660154462,1.2138281,2.890625,1.0
7500,1.0748107,1.0846099675969874,1.0846099675969874,1.1698828,2.5390070921985815,1.0
8000,1.0822604,1.0874026332582747,1.0874026332582747,1.133416,2.25974025974026,1.0
8500,1.085208,1.0900599135610158,1.0900599135610158,1.1044095,1.9940119760479043,1.0
9000,1.0849307,1.0917514441377025,1.0917514441377025,1.0853884,1.8248587570621468,1.0
9500,1.080448,1.0935450035428245,1.0935450035428245,1.0348397,1.6402116402116402,1.0
10000,1.0843877,1.0958252705416633,1.0958252705416633,0.9949041,1.4223300970873787,1.0
