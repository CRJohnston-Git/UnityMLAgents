# 学习环境示例

Unity ML-Agents 包含一个扩展的环境示例集合，
这些示例演示了该平台的各种功能。环境位于 
`unity-environment/Assets/ML-Agents/Examples` 中并概括在了下方。
此外，我们的
[第一个 ML 挑战](https://connect.unity.com/challenges/ml-agents-1)
包含了由社区创建的环境。

此页仅概述了我们提供的示例环境。要了解更多
关于如何设计和构建您自己的环境的信息，请参阅
[创建新的学习环境](Learning-Environment-Create-New.md)
页面。

如果您想提交自己的环境，请参阅我们的
[贡献指南](../CONTRIBUTING.md)页面。

## Basic

![Basic](images/basic.png)

* 设置：一种线性移动任务，在此任务中 agent 必须向左或向右移动到奖励状态。
* 目标：移动到最高奖励状态。
* Agent：环境包含一个链接到单个 brain 的 agent。
* Agent 奖励函数：
    * 达到次优状态时 +0.1。
    * 达到最优状态时 +1.0。
* Brain：一个有以下观测/运动空间的 brain。
    * 向量观测空间：（离散）一个变量，对应于当前状态。
    * 向量运动空间：（离散）两个可能的动作（向左移动、向右移动）。
    * 视觉观测：0
* 重置参数：无

## 3DBall: 3D Balance Ball

![3D Balance Ball](images/balance.png)

* 设置：一种平衡球任务，在此任务中 agent 需要控制平台。
* 目标：agent 必须平衡平台，以尽可能长时间在平台上保持球不掉落。
* Agent：环境包含 12 个全部链接到单个 brain 的同类 agent。
* Agent 奖励函数：
    * 球在平台上保持不掉下的每一步都 +0.1。
    * 球掉下平台时 -1.0。
* Brain：一个有以下观测/运动空间的 brain。
    * 向量观测空间：（连续）8 个变量，对应于平台的旋转以及球的位置、旋转和速度。
    * 向量观测空间（硬版本）：（连续）5 个变量，对应于平台的旋转以及球的位置和旋转。
    * 向量运动空间：（连续）大小为 2，其中一个值对应于 X 旋转，而另一个值对应于 Z 旋转。
    * 视觉观测：0
* 重置参数：无

## GridWorld

![GridWorld](images/gridworld.png)

* 设置：一个典型网格世界任务版本。场景包含 agent、目标和障碍。
* 目标：agent 必须在网格中避开障碍的同时导航到目标。
* Agent：环境包含一个链接到单个 brain 的 agent。
* Agent 奖励函数：
    * 每一步 -0.01。
    * agent 导航到目标网格位置时 +1.0（场景结束）。
    * agent 导航到障碍物时 -1.0（场景结束）。
* Brain：一个有以下观测/运动空间的 brain。
    * 向量观测空间：无
    * 向量运动空间：（离散）大小为 4，对应于基本方向的移动。
    * 视觉观测：一个，对应于 GridWorld 自上而下的视图。
* 重置参数：三个，对应于网格大小、障碍物数量和目标数量。


## Tennis

![Tennis](images/tennis.png)

* 设置：agent 控制球拍将球弹过球网的双人游戏。
* 目标：agent 必须在彼此之间弹起网球，同时不能丢球或发球出界。
* Agent：环境包含两个链接到单个 brain（名为 TennisBrain）的 agent。在训练之后，您可以将另一个名为 MyBrain 的 brain 附加到其中一个 agent，从而与经过训练的模型进行游戏比赛。
* Agent 奖励函数（独立）：
    * agent 击球过网时 +0.1。
    * agent 让球落入自己的范围或者击球出界时 -0.1。
* Brain：一个有以下观测/运动空间的 brain。
    * 向量观测空间：（连续）8 个变量，对应于球和球拍的位置和速度。
    * 向量运动空间：（连续）大小为 2，对应于朝向球网或远离球网的运动，以及跳跃。
    * 视觉观测：无
* 重置参数：一个，对应于球的大小。

## Push Block

![Push](images/push.png)

* 设置：一个平台环境，agent 可以在该环境中推动推块。
* 目标：agent 必须将推块推向目标。
* Agent：环境包含一个链接到单个 brain 的 agent。
* Agent 奖励函数：
    * 每一步 -0.0025。
    * 推块接触到目标时 +1.0。
* Brain：一个有以下观测/运动空间的 brain。
    * 向量观测空间：（连续）15 个变量，对应于 agent、推块和目标的位置和速度。
    * 向量运动空间：（连续）大小为 2，对应于 X 和 Z 方向的移动。
    * 视觉观测：无。
* 重置参数：无。

## Wall Jump

![Wall](images/wall.png)

* 设置：一个平台环境，agent 可以在该环境中跳过墙。
* 目标：agent 必须使用块来缩放墙并到达目标。
* Agent：环境包含一个链接到两个不同 brain 的 agent。agent 链接到的 brain 根据墙的高度而变化。
* Agent 奖励函数：
    * 每一步 -0.0005。
    * agent 接触到目标时 +1.0。
    * agent 掉下平台时 -1.0。
* Brain：一个有以下观测/运动空间的 brain。
    * 向量观测空间：（连续）16 个变量，对应于 agent、推块和目标的位置和速度以及墙的高度。
    * 向量运动空间：（离散）大小为 74，对应于 14 个射线投射，每个射线投射可检测 4 个可能的物体，加上 agent 的全局位置以及 agent 是否落地。
    * 视觉观测：无。
* 重置参数：4，对应于可能的墙壁的高度。

## Reacher

![Tennis](images/reacher.png)

* 设置：可以移动到目标位置的双关节臂。
* 目标：agent 必须将手移动到目标位置，并保持在此处。
* Agent：环境包含 32 个链接到单个 brain 的 agent。
* Agent 奖励函数（独立）：
    * 每一步 agent 手处于目标位置时 +0.1。
* Brain：一个有以下观测/运动空间的 brain。
    * 向量观测空间：（连续）26 个变量，对应于两个机械臂 Rigidbody 的位置、旋转、速度和角速度。
    * 向量运动空间：（连续）大小为 4，对应于适用于两个关节的扭矩。
    * 视觉观测：无
* 重置参数：两个，对应于目标大小和目标移动速度。

## Crawler

![Crawler](images/crawler.png)

* 设置：一种有 4 个手臂和 4 个前臂的生物。
* 目标：agent 必须沿 x 轴移动其身体而不会跌倒。
* Agent：环境包含 3 个链接到单个 brain 的 agent。
* Agent 奖励函数（独立）：
    * +1 乘以 x 方向的速度
    * 跌倒时 -1。
    * -0.01 乘以动作平方
    * -0.05 乘以 y 位置变化
    * -0.05 乘以 z 方向的速度
* Brain：一个有以下观测/运动空间的 brain。
    * 向量观测空间：（连续）117 个变量，对应于每个肢体的位置、旋转、速度和角速度以及身体的加速度和角速度。
    * 向量运动空间：（连续）大小为 12，对应于适用于 12 个关节的扭矩。
    * 视觉观测：无
* 重置参数：无

## Banana Collector

![Banana](images/banana.png)

* 设置：一种包含多个 agent 的环境，这些 agent 争相收集香蕉。
* 目标：agent 必须学习尽可能接近更多的黄色香蕉，同时避开红色香蕉。
* Agent：环境包含 10 个链接到单个 brain 的 agent。
* Agent 奖励函数（独立）：
    * 接触黄色香蕉时 +1
    * 接触红色香蕉时 -1。
* Brain：一个有以下观测/运动空间的 brain。
    * 向量观测空间：（连续）51 个，对应于 agent 的速度以及 agent 前进方向周围对物体进行基于射线的感知。
    * 向量运动空间：（连续）大小为 3，对应于向前移动、y 轴旋转以及是否使用激光使其他 agent 瘫痪。
    * 视觉观测（可选）：每个 agent 的第一人称视图。
* 重置参数：无

## Hallway

![Hallway](images/hallway.png)

* 设置：在一个环境中，agent 需要在房间内查找信息、记住信息并使用信息移动到正确目标。
* 目标：移动到与房间内的方块的颜色相对应的目标。
* Agent：环境包含一个链接到单个 brain 的 agent。
* Agent 奖励函数（独立）：
    * 移动到正确目标时 +1。
    * 移动到错误目标时 -0.1。
    * 存在性惩罚 -0.0003。
* Brain：一个有以下观测/运动空间的 brain：
    * 向量观测空间：（连续）30，对应于可检测物体、目标和墙壁的局部射线投射。
    * 向量运动空间：（离散）4，对应于 agent 旋转和前进/后退运动。
    * 视觉观测（可选）：agent 的第一人称视图。
* 重置参数：无

## Bouncer

![Bouncer](images/bouncer.png)

* 设置：在一个环境中，agent 需要按需决策。agent 必须决定在接触地面时如何进行下一次弹跳。
* 目标：抓住漂浮的香蕉。跳跃次数有限。
* Agent：环境包含一个链接到单个 brain 的 agent。
* Agent 奖励函数（独立）：
    * 抓住香蕉时 +1。
    * 弹跳出界时 -1。
    * -0.05 乘以动作平方。能量消耗惩罚。
* Brain：一个有以下观测/运动空间的 brain：
    * 向量观测空间：（连续）6，对应于 agent 和香蕉的局部位置。
    * 向量运动空间：（连续）3，对应于 agent 为跳跃所用的力。
    * 视觉观测：无
* 重置参数：无

## Soccer Twos

![SoccerTwos](images/soccer.png)

* 设置：在一个环境中，四个 agent 在 2 对 2 玩具足球比赛中比赛。
* 目标：
    * 前锋：让球进入对手的球门。
    * 守门员：防止球进入自己的球门。
* Agent：环境包含四个 agent，其中两个链接到一个 brain（前锋），两个链接到另一个 brain（守门员）。
* Agent 奖励函数（非独立）：
    * 前锋：
        * 球进入对手球门时 +1。
        * 球进入自己队的球门时 -0.1。
        * 存在性惩罚 -0.001。
    * 守门员：
        * 球进入自己队的球门时 -1。
        * 球进入对手球门时 +0.1。
        * 存在性奖励 +0.001。
* Brain：两个有以下观测/运动空间的 brain：
    * 向量观测空间：（连续）112，对应于局部的 14 个射线投射，每个射线投射可检测 7 个可能的物体类型，以及物体的距离。感知范围是 agent 前面的 180 度视角。
    * 向量运动空间：（离散）
        * 前锋：6，对应于前进、后退、侧身移动以及旋转。
        * 守门员：4，对应于前进、后退、侧身移动。
    * 视觉观测：无
* 重置参数：无
